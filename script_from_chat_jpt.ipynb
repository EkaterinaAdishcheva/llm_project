{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a06702-9e88-4a6d-9607-96bafeb5f676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Загрузим модель для векторизации текстов\n",
    "sentence_transformer_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1d6189-d572-4e38-b6ce-c08b093fef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример кулинарных рецептов\n",
    "recipes = [\n",
    "    \"Спагетти Болоньезе: отварить макароны, приготовить говяжий фарш с томатным соусом и чесноком\",\n",
    "    \"Веганский салат: смешать салат, помидоры, огурцы и оливковое масло\",\n",
    "    \"Куриное карри: приготовить курицу с порошком карри, луком, чесноком и кокосовым молоком\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec7a7c6-0b64-49b7-8f44-82c4f0fd3a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем рецепты в эмбеддинги\n",
    "recipe_embeddings = sentence_transformer_model.encode(recipes)\n",
    "\n",
    "# Создадим FAISS индекс\n",
    "dimension = recipe_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(np.array(recipe_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ff4fca-3889-4ac0-83b2-5ef2be720f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример запроса от пользователя\n",
    "user_query = \"Как приготовить веганский салат?\"\n",
    "\n",
    "# Преобразуем запрос в эмбеддинг\n",
    "query_embedding = sentence_transformer_model.encode([user_query])\n",
    "\n",
    "# Ищем ближайшие рецепты\n",
    "D, I = index.search(np.array(query_embedding), k=2)\n",
    "\n",
    "# Извлекаем наиболее релевантные рецепты\n",
    "relevant_recipes = [recipes[i] for i in I[0]]\n",
    "print(\"Relevant recipes:\", relevant_recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe25964e-5a8c-44aa-b620-493af9b8871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# Choose the appropriate model\n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"  # or \"microsoft/Phi-3-mini-128k-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a70693-ecff-4487-8f34-a4d33876c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c897c7-8f55-49a0-9626-3d911e4374f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Конкатенируем извлеченные рецепты с запросом пользователя\n",
    "input_text = f\"User query: {user_query}\\nСоответствующие рецепты: {', '.join(relevant_recipes)}\\nДайте четкий и лаконичный ответ:\"\n",
    "\n",
    "# Токенизация и генерация ответа\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(inputs[\"input_ids\"], max_length=150, num_return_sequences=1)\n",
    "\n",
    "# Декодируем результат\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b3cc01-d777-47e9-be4e-cb21566c44a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция DeepSeek-R1 для оптимизации результатов поиска и генерации\n",
    "def deepseek_r1_optimization(query, relevant_recipes):\n",
    "    # Здесь может быть дополнительная логика для улучшения выбора ответа\n",
    "    # Например, более точная фильтрация или уточнение запроса на основе DeepSeek-R1\n",
    "    optimized_recipes = relevant_recipes  # Здесь может быть дополнительная логика для уточнения\n",
    "    return optimized_recipes\n",
    "\n",
    "# Преобразуем запрос в эмбеддинг\n",
    "query_embedding = sentence_transformer_model.encode([user_query])\n",
    "\n",
    "# Ищем ближайшие рецепты\n",
    "D, I = index.search(np.array(query_embedding), k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470dc7b7-b83b-4e9b-9709-a3fe2e81ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Извлекаем наиболее релевантные рецепты\n",
    "relevant_recipes = [recipes[i] for i in I[0]]\n",
    "\n",
    "# Применяем DeepSeek-R1 для оптимизации полученных рецептов\n",
    "optimized_recipes = deepseek_r1_optimization(user_query, relevant_recipes)\n",
    "\n",
    "# Генерация ответа с использованием Llama\n",
    "def generate_response(query, relevant_recipes, tokenizer, model):\n",
    "    input_text = f\"User query: {user_query}\\nСоответствующие рецепты: {', '.join(relevant_recipes)}\\nДайте четкий и лаконичный ответ:\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(inputs[\"input_ids\"], max_length=150, num_return_sequences=1)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "# Генерируем ответ\n",
    "response = generate_response(user_query, optimized_recipes, tokenizer, model)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af7bbb5-01e0-43bb-8b64-2295ebd6a3be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm_venv)",
   "language": "python",
   "name": "llm_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
